# Rust Visibility Optimization Notes

Status: **post sin_cos + polygon terrain support** — polygon overhead is the new optimization frontier

## Context

The visibility system computes per-observer visibility polygons via angular-sweep raycasting, then uses those polygons for several scoring metrics:

- **Overall visibility**: Grid sample points inside the visibility polygon vs total grid points.
- **DZ hideability**: Whether the visibility polygon overlaps the opponent's expanded deployment zone (polygon-polygon intersection test).
- **Objective hidability**: Whether objective-vicinity sample points have line of sight to the opponent's DZ (vis poly computed from each sample point, then polygon-polygon intersection with expanded DZ).

The angular-sweep raycasting (`compute_visibility_polygon`) casts rays toward segment endpoints (±epsilon), finds the nearest intersection per ray, and forms the visibility polygon. The hot loop is O(R × S) where R = rays, S = segments, reduced to O(R × k) by angular bucketing.

Real-world workloads: ~100-200 unique endpoints → ~300-600 rays, ~40-80 terrain segments + 4 table boundary segments.

## Benchmark Setup (IMPORTANT)

The benchmark fixtures in `benches/generate_bench.rs` were originally using **2" tall crates**, which are below the 4" `min_blocking_height` threshold. This meant the "visibility" benchmarks weren't actually testing the intersection loop at all — every observer hit the fast path (0 segments). The fixtures were fixed to use **5" tall crates** as part of this work.

Baseline numbers (with corrected 5" crates, before any optimization):
- `visibility_50`: 872 ms
- `visibility_100`: 3.80 s
- `mission_hna`: 5.70 s

### Benchmark fixtures (35-case pairwise covering array)

The benchmarks use a pairwise (all-pairs) covering array to exercise all 2-way parameter interactions with minimal test cases. Generated by `benches/generate_fixtures.py`.

**Parameters (10):**
- **Table size** (3): 44×30 (incursion), 60×44 (strike), 90×44 (onslaught)
- **Symmetry** (2): off, on (forced off when mission=none)
- **Mission** (7): none, Hammer & Anvil, Dawn of War, Tipping Point, Sweeping Engagement, Crucible of Battle, Search & Destroy
- **Terrain** (3): crates-only (5" tall rects), WTC mixed (rects: crates + ruins + walls), WTC+poly (WTC rects + polygon shapes: 24-gon tank + 20-vertex kidney-bean woods)
- **Steps** (4): 10, 20, 50, 100
- **Feature gap** (2): 0 or 5.2" (`min_feature_gap_inches`)
- **Edge gap** (2): 0 or 5.2" (`min_edge_gap_inches`)
- **All-feature gap** (2): 0 or 3" (`min_all_feature_gap_inches`)
- **All-edge gap** (2): 0 or 3" (`min_all_edge_gap_inches`)
- **Replicas** (4): 1, 2, 4, 8 (`num_replicas` for parallel tempering)

**Constraints:**
- mission=none → symmetry forced to off
- steps >= 50 OR table >= 60×44 → replicas != 8
- steps >= 100 OR table >= 90×44 → replicas != 4

All 35 cases use seed=42, visibility enabled, scoring_targets matching UI defaults (overall=30%/w1, dz_hide=70%/w5, obj_hide=50%/w5). Mission cases include precomputed `expanded_polygons` (6" DZ expansion via shapely), so the DZ hideability polygon-polygon intersection path is actually exercised.

Gap suffix `_gFEAA` encodes gap params as 4-bit flags: F=feature_gap, E=edge_gap, A=all_feature_gap, A=all_edge_gap (0=off, 1=on: 5.2" for F/E, 3" for A/A). Replica suffix `_rN` encodes num_replicas.

| # | Benchmark | Table | Sym | Mission | Terrain | Steps | Gaps | Rep |
|---|-----------|-------|-----|---------|---------|-------|------|-----|
| 01 | `90x44_crates_none_nosym_10_g0000_r1` | 90×44 | off | none | crates | 10 | 0000 | 1 |
| 02 | `44x30_wtc_none_nosym_20_g1010_r8` | 44×30 | off | none | WTC | 20 | 1010 | 8 |
| 03 | `60x44_crates_none_nosym_50_g1101_r4` | 60×44 | off | none | crates | 50 | 1101 | 4 |
| 04 | `44x30_wtc_none_nosym_100_g0111_r2` | 44×30 | off | none | WTC | 100 | 0111 | 2 |
| 05 | `44x30_wtc_HnA_nosym_10_g1001_r8` | 44×30 | off | HnA | WTC | 10 | 1001 | 8 |
| 06 | `90x44_crates_HnA_sym_20_g0100_r1` | 90×44 | on | HnA | crates | 20 | 0100 | 1 |
| 07 | `60x44_wtc_HnA_nosym_50_g0110_r4` | 60×44 | off | HnA | WTC | 50 | 0110 | 4 |
| 08 | `60x44_crates_HnA_sym_100_g1011_r2` | 60×44 | on | HnA | crates | 100 | 1011 | 2 |
| 09 | `44x30_wtc_DoW_sym_10_g0110_r8` | 44×30 | on | DoW | WTC | 10 | 0110 | 8 |
| 10 | `60x44_crates_DoW_nosym_20_g1001_r4` | 60×44 | off | DoW | crates | 20 | 1001 | 4 |
| 11 | `90x44_crates_DoW_sym_50_g0011_r2` | 90×44 | on | DoW | crates | 50 | 0011 | 2 |
| 12 | `90x44_wtc_DoW_nosym_100_g1100_r1` | 90×44 | off | DoW | WTC | 100 | 1100 | 1 |
| 13 | `60x44_wtc_TipPt_sym_10_g1010_r2` | 60×44 | on | TipPt | WTC | 10 | 1010 | 2 |
| 14 | `44x30_crates_TipPt_nosym_20_g0101_r8` | 44×30 | off | TipPt | crates | 20 | 0101 | 8 |
| 15 | `44x30_crates_TipPt_sym_50_g1001_r4` | 44×30 | on | TipPt | crates | 50 | 1001 | 4 |
| 16 | `90x44_wtc_TipPt_nosym_100_g0110_r1` | 90×44 | off | TipPt | WTC | 100 | 0110 | 1 |
| 17 | `60x44_crates_SwpEng_nosym_10_g0101_r4` | 60×44 | off | SwpEng | crates | 10 | 0101 | 4 |
| 18 | `44x30_wtc_SwpEng_sym_20_g1010_r8` | 44×30 | on | SwpEng | WTC | 20 | 1010 | 8 |
| 19 | `90x44_crates_SwpEng_nosym_50_g1101_r2` | 90×44 | off | SwpEng | crates | 50 | 1101 | 2 |
| 20 | `60x44_wtc_SwpEng_sym_100_g0010_r1` | 60×44 | on | SwpEng | WTC | 100 | 0010 | 1 |
| 21 | `44x30_crates_Crucible_sym_10_g1000_r8` | 44×30 | on | Crucible | crates | 10 | 1000 | 8 |
| 22 | `60x44_wtc_Crucible_nosym_20_g0111_r2` | 60×44 | off | Crucible | WTC | 20 | 0111 | 2 |
| 23 | `60x44_wtc_Crucible_sym_50_g0110_r4` | 60×44 | on | Crucible | WTC | 50 | 0110 | 4 |
| 24 | `90x44_crates_Crucible_nosym_100_g1001_r1` | 90×44 | off | Crucible | crates | 100 | 1001 | 1 |
| 25 | `60x44_wtc_SnD_nosym_10_g0111_r4` | 60×44 | off | SnD | WTC | 10 | 0111 | 4 |
| 26 | `44x30_crates_SnD_sym_20_g1000_r8` | 44×30 | on | SnD | crates | 20 | 1000 | 8 |
| 27 | `44x30_wtc_SnD_nosym_50_g0010_r1` | 44×30 | off | SnD | WTC | 50 | 0010 | 1 |
| 28 | `90x44_crates_SnD_sym_100_g1101_r2` | 90×44 | on | SnD | crates | 100 | 1101 | 2 |
| 29 | `60x44_wtcPoly_none_nosym_20_g0101_r4` | 60×44 | off | none | WTC+poly | 20 | 0101 | 4 |
| 30 | `44x30_wtcPoly_HnA_sym_10_g1010_r8` | 44×30 | on | HnA | WTC+poly | 10 | 1010 | 8 |
| 31 | `90x44_wtcPoly_DoW_nosym_50_g0011_r2` | 90×44 | off | DoW | WTC+poly | 50 | 0011 | 2 |
| 32 | `60x44_wtcPoly_TipPt_sym_100_g1100_r1` | 60×44 | on | TipPt | WTC+poly | 100 | 1100 | 1 |
| 33 | `44x30_wtcPoly_SwpEng_nosym_10_g0110_r8` | 44×30 | off | SwpEng | WTC+poly | 10 | 0110 | 8 |
| 34 | `90x44_wtcPoly_Crucible_sym_20_g1001_r1` | 90×44 | on | Crucible | WTC+poly | 20 | 1001 | 1 |
| 35 | `44x30_wtcPoly_SnD_sym_50_g0000_r2` | 44×30 | on | SnD | WTC+poly | 50 | 0000 | 2 |

Criterion config: `sample_size(10)`, `warm_up_time(500ms)`, `measurement_time(3s)` — total suite runtime ~10 minutes.

For quick iteration, filter to specific cases: `cargo bench -- 60x44_crates_HnA` or `cargo bench -- _r8` (all 8-replica cases).

### Baseline results (February 2026, 10-parameter suite)

*Note: cases 01-28 are the original rect-only baseline. Cases 29-35 were added later with the wtcPoly catalog (polygon terrain shapes). The "baseline" numbers for 01-28 predate polygon support in the engine; the numbers for 29-35 are from the first run after polygon support was added.*

| # | Benchmark | Rep | Mean |
|---|-----------|-----|------|
| 01 | `90x44_crates_none_nosym_10_g0000_r1` | 1 | 17.3 ms |
| 02 | `44x30_wtc_none_nosym_20_g1010_r8` | 8 | 46.0 ms |
| 03 | `60x44_crates_none_nosym_50_g1101_r4` | 4 | 162 ms |
| 04 | `44x30_wtc_none_nosym_100_g0111_r2` | 2 | 119 ms |
| 05 | `44x30_wtc_HnA_nosym_10_g1001_r8` | 8 | 72.9 ms |
| 06 | `90x44_crates_HnA_sym_20_g0100_r1` | 1 | 148 ms |
| 07 | `60x44_wtc_HnA_nosym_50_g0110_r4` | 4 | 407 ms |
| 08 | `60x44_crates_HnA_sym_100_g1011_r2` | 2 | 877 ms |
| 09 | `44x30_wtc_DoW_sym_10_g0110_r8` | 8 | 88.4 ms |
| 10 | `60x44_crates_DoW_nosym_20_g1001_r4` | 4 | 116 ms |
| 11 | `90x44_crates_DoW_sym_50_g0011_r2` | 2 | 646 ms |
| 12 | `90x44_wtc_DoW_nosym_100_g1100_r1` | 1 | 842 ms |
| 13 | `60x44_wtc_TipPt_sym_10_g1010_r2` | 2 | 70.8 ms |
| 14 | `44x30_crates_TipPt_nosym_20_g0101_r8` | 8 | 162 ms |
| 15 | `44x30_crates_TipPt_sym_50_g1001_r4` | 4 | 300 ms |
| 16 | `90x44_wtc_TipPt_nosym_100_g0110_r1` | 1 | 893 ms |
| 17 | `60x44_crates_SwpEng_nosym_10_g0101_r4` | 4 | 58.3 ms |
| 18 | `44x30_wtc_SwpEng_sym_20_g1010_r8` | 8 | 271 ms |
| 19 | `90x44_crates_SwpEng_nosym_50_g1101_r2` | 2 | 361 ms |
| 20 | `60x44_wtc_SwpEng_sym_100_g0010_r1` | 1 | **1.11 s** |
| 21 | `44x30_crates_Crucible_sym_10_g1000_r8` | 8 | 82.0 ms |
| 22 | `60x44_wtc_Crucible_nosym_20_g0111_r2` | 2 | 91.4 ms |
| 23 | `60x44_wtc_Crucible_sym_50_g0110_r4` | 4 | 515 ms |
| 24 | `90x44_crates_Crucible_nosym_100_g1001_r1` | 1 | 790 ms |
| 25 | `60x44_wtc_SnD_nosym_10_g0111_r4` | 4 | 69.5 ms |
| 26 | `44x30_crates_SnD_sym_20_g1000_r8` | 8 | 185 ms |
| 27 | `44x30_wtc_SnD_nosym_50_g0010_r1` | 1 | 156 ms |
| 28 | `90x44_crates_SnD_sym_100_g1101_r2` | 2 | **1.23 s** |
| 29 | `60x44_wtcPoly_none_nosym_20_g0101_r4` | 4 | 54.8 ms |
| 30 | `44x30_wtcPoly_HnA_sym_10_g1010_r8` | 8 | 133 ms |
| 31 | `90x44_wtcPoly_DoW_nosym_50_g0011_r2` | 2 | 508 ms |
| 32 | `60x44_wtcPoly_TipPt_sym_100_g1100_r1` | 1 | **1.60 s** |
| 33 | `44x30_wtcPoly_SwpEng_nosym_10_g0110_r8` | 8 | 58.2 ms |
| 34 | `90x44_wtcPoly_Crucible_sym_20_g1001_r1` | 1 | 222 ms |
| 35 | `44x30_wtcPoly_SnD_sym_50_g0000_r2` | 2 | 356 ms |

**Observations:**
- Replicas add significant cost: rep=8 cases on small tables (44×30, 10-20 steps) run ~3-8x slower than equivalent rep=1. Rep=2 and rep=4 scale roughly linearly.
- The heaviest case is now 32 (60×44 wtcPoly TipPt sym 100 r1) at 1.60s. Previous heaviest: 28 (90×44 SnD sym 100 r2) at 1.23s. The polygon overhead (more edges per shape) is the main driver.
- The replica exclusion constraints keep benchmark runtime manageable — 8 replicas only on small/fast workloads, 4 replicas excluded from onslaught and 100-step cases.
- Symmetry remains expensive: sym cases are ~2-3x slower than nosym at same step count.
- Gap enforcement adds ~5-15% overhead on mutation-heavy workloads.
- 10-step r1 cases remain fast (~17ms) for quick regression checks.

**Polygon terrain overhead (wtcPoly vs rect-only catalogs):**
The WTC+poly catalog adds a 24-gon industrial tank (5" tall, opaque) and a 20-vertex kidney-bean woods (flat). Compared to rect-only catalogs at similar parameters:
- ~1.5-2x overhead on comparable configurations (closest comparison: 44×30 HnA 10step r8: wtc=69.6ms vs wtcPoly=132.7ms = 1.9x)
- The overhead comes from: (a) `polygons_overlap()` is O(E_a × E_b) vs `obbs_overlap()` which uses SAT with 4 axes; polygon shapes have 20-24 edges vs 4. (b) `obb_distance()` iterates over all edges for gap enforcement. (c) `precompute_segments()` in visibility generates more wall segments per polygon shape.
- The tank (24-gon, 5" tall) is particularly expensive: it's opaque, so it generates 24 visibility segments, and its collision footprint is checked via polygons_overlap (24×N edges) rather than SAT (4 axes).

## Committed Optimizations

### 1. Angular bucketing (commit `47e451c`)
Partition segments by angular extent into 64 buckets. Each ray only tests segments in its bucket, reducing work from O(R×S) to O(R×k) where k ≈ average segments per bucket.

- visibility_50: 872ms → 688ms (**-21%**)
- visibility_100: 3.80s → 2.19s (**-42%**)
- mission_hna: 5.70s → 4.76s (**-16%**)

### 2. ~~Trig reduction in ray generation~~ (commit `43c1bfa`, **reverted**)
Originally replaced 6 cos/sin calls per endpoint with 1 sqrt + small-angle rotation matrix for ±epsilon rays. **Reverted for FP parity**: the rotation matrix `ndx * cos_eps ± ndz * sin_eps` produces different IEEE 754 results than Python's `cos(angle ± eps)` / `sin(angle ± eps)`, causing visibility polygon vertex differences that propagated into DZ PIP boundary tests. The code now uses `cos(angle ± eps)` / `sin(angle ± eps)` (4 trig calls per endpoint) to match Python exactly.

### 3. Inlined intersection + removed polygon buffer (commit `dfd7351`)
Inline `ray_segment_intersection` in the hot loop to enable early exit when `t >= min_t` (skips u computation). Eliminate intermediate `polygon` Vec, write directly to result.

- visibility_50: 688ms → 583ms (**-15%**)
- visibility_100: 2.19s → 1.84s (**-16%**)
- mission_hna: 4.76s → 4.88s (~same)

*Note: numbers updated to reflect opt #2 revert (baseline is post-bucketing, not post-trig-reduction).*

### 4. Rayon parallel observer loop (commit `3f719bc`)
Parallelize the observer loop in `compute_layout_visibility` using `rayon::par_iter().fold().reduce()`. Each thread gets a `Box<ThreadAccum>` with its own working buffers and accumulators. Merge via sum for ratios/counts and OR for boolean seen arrays.

Note: rayon parallelism changes the order observers are processed, but the final result is mathematically identical (addition is commutative). Parity with Python engine is maintained.

### 5–6. ~~Z-sorted binary search for DZ PIP~~ (**superseded by architecture change**)
Optimizations #5 and #6 introduced Z-sorted binary search (`DzSortedSamples`, `fraction_of_dz_visible_zsorted`, `pip_zsorted_update_seen`) for point-in-polygon testing against DZ sample grids. These were the biggest wins on mission workloads (~49% and ~41% respectively on `mission_hna`).

**These optimizations are now largely superseded.** The DZ visibility system was refactored (commit `703487f`) to replace PIP-based grid sampling with polygon-polygon intersection (`polygons_overlap`). The old `dz_visibility` and `dz_to_dz_visibility` metrics (which tested hundreds of DZ sample points against each observer's visibility polygon) were replaced by a single `dz_hideability` metric that tests whether the visibility polygon overlaps the opponent's expanded DZ polygon — a direct geometric check with no sampling.

Z-sorted PIP code has been fully removed from production paths. Objective hidability was refactored to compute vis polys from objective-vicinity sample points and check polygon-polygon intersection with expanded DZ polygons (same approach as DZ hideability). The `DzSortedSamples` struct and `pip_zsorted_update_seen` function remain only in `#[cfg(test)]` code.

### 7. DZ visibility: polygon-polygon intersection (commit `703487f`)
Replace expensive per-observer PIP sampling for DZ metrics with direct polygon-polygon intersection testing. DZ polygons are expanded by a fixed radius (using shapely in Python, passed to Rust as precomputed `expanded_polygons`). Each observer tests whether its visibility polygon overlaps the opponent's expanded DZ — a single `polygons_overlap()` call per DZ pair, using edge-edge intersection + vertex containment.

This eliminates the entire DZ sample grid, Z-sorted binary search for DZ PIP, and complex batch encoding logic. The new `dz_hideability` metric is both faster and more precise (exact geometric intersection vs grid approximation).

- visibility_50: ~201ms → ~191ms (no DZs — within noise)
- visibility_100: ~719ms → ~733ms (no DZs — within noise)
- **mission_hna: ~629ms → ~364ms (-42%)**
- **mission_ruins: ~371ms → ~192ms (-48%)**

### 8. AABB early-exit for polygons_overlap (precomputed DZ AABBs)
Precompute axis-aligned bounding boxes for each expanded DZ polygon (constant per layout). In the per-observer hot loop, compute the vis_poly AABB on-the-fly and reject non-overlapping pairs before the expensive O(E_A x E_B) edge-edge intersection tests.

Key design choice: a naive approach that computes *both* AABBs inside `polygons_overlap` caused a regression on some workloads (+9% on SwpEng_nosym_100) because when AABBs always overlap, the O(n_b) scan of the static DZ polygon was pure overhead. By precomputing the DZ AABB once and only computing the vis_poly AABB per call (`polygons_overlap_aabb`), the per-call cost is reduced to O(n_vis_poly) + 4 comparisons.

Impact varies by mission type and table size. Largest wins on large-table symmetric cases where many observers have visibility polygons that don't reach distant DZs:

- **90x44_wtc_HnA_sym_20**: 219 ms -> 181 ms (**-17.5%**)
- **90x44_wtc_DoW_sym_100**: 1717 ms -> 1473 ms (**-14.2%**)
- **90x44_crates_Crucible_nosym_100**: 787 ms -> 712 ms (**-9.5%**)
- **44x30_wtc_HnA_nosym_50**: 157 ms -> 144 ms (**-8.4%**)
- **60x44_crates_HnA_sym_100**: 667 ms -> 621 ms (**-7.0%**)
- Non-mission benchmarks: unaffected (no `polygons_overlap` calls)
- No regressions observed

### 9. FxHash for endpoint deduplication and objective hidability lookups
Replace the standard library `HashSet<(u64, u64)>` (SipHash-2-4, cryptographic quality) with a custom inline FxHash hasher for all integer-keyed hash sets/maps in the visibility hot paths. SipHash provides DoS resistance which is unnecessary for non-adversarial keys like `f64::to_bits()` pairs and `usize` indices. FxHash uses a single `(rotate_left(5) ^ key).wrapping_mul(MAGIC)` per 8-byte chunk -- roughly 5-10x faster per hash operation.

Affected data structures:
- `VisBuffers::endpoint_seen: FxHashSet<(u64, u64)>` -- per-observer endpoint dedup (hot path)
- `candidate_origins: FxHashSet<(u64, u64)>` -- objective hidability square candidates
- `pt_index: FxHashMap<(u64, u64), usize>` -- objective sample point lookup
- `hidden: FxHashSet<usize>` -- hidden index set for objective hidability

No external dependency added: the FxHasher is implemented inline (~25 lines) in `visibility.rs`. The change is internal-only -- produces identical output since the same set of unique endpoints is collected regardless of hash function.

Broad improvement across all workloads (5-15% typical, up to 21% on some cases):

| # | Benchmark | Before | After | Change |
|---|-----------|--------|-------|--------|
| 01 | `44x30_crates_none_nosym_10_g0000` | 10.1 ms | 9.4 ms | **-7%** |
| 02 | `60x44_wtc_none_nosym_20_g1010` | 29.2 ms | 27.8 ms | **-5%** |
| 03 | `90x44_crates_none_nosym_50_g1101` | 145 ms | 141 ms | -3% |
| 04 | `44x30_wtc_none_nosym_100_g0111` | 103 ms | 98.8 ms | **-4%** |
| 06 | `90x44_wtc_HnA_sym_20_g0100` | 187 ms | 163 ms | **-13%** |
| 08 | `60x44_crates_HnA_sym_100_g1011` | 635 ms | 574 ms | **-10%** |
| 09 | `90x44_wtc_DoW_nosym_10_g0110` | 36.1 ms | 31.8 ms | **-11%** |
| 10 | `44x30_crates_DoW_sym_20_g1001` | 38.1 ms | 34.8 ms | **-11%** |
| 11 | `60x44_crates_DoW_nosym_50_g0011` | 201 ms | 180 ms | **-10%** |
| 12 | `90x44_wtc_DoW_sym_100_g1100` | 1468 ms | 1364 ms | **-7%** |
| 14 | `60x44_crates_TipPt_nosym_20_g0101` | 58.9 ms | 54.1 ms | **-9%** |
| 16 | `44x30_wtc_TipPt_nosym_100_g0110` | 340 ms | 309 ms | **-9%** |
| 17 | `60x44_wtc_SwpEng_sym_10_g0101` | 49.2 ms | 36.3 ms | **-21%** |
| 18 | `90x44_crates_SwpEng_nosym_20_g1010` | 83.1 ms | 71.3 ms | **-15%** |
| 25 | `44x30_crates_SnD_nosym_10_g0111` | 15.4 ms | 13.2 ms | **-14%** |
| 28 | `44x30_crates_SnD_sym_100_g1101` | 212 ms | 190 ms | **-10%** |

(Selected representative cases; 25/28 benchmarks improved by 5%+ with no regressions.)

### 10. Pseudoangle for bucket assignment (replacing atan2 in bucketing)

Replace `atan2` calls in the segment bucketing loop and ray bucket lookup with a cheap pseudoangle function `pseudoangle(dx, dz) = if dz >= 0 { 3 - dx/(|dx|+|dz|) } else { 1 + dx/(|dx|+|dz|) }`. The pseudoangle maps monotonically from [0, 4) as angle goes from -pi to pi, so it preserves sort order and bucket consistency.

This eliminates 2 atan2 calls per segment per observer in the bucketing loop (lines 438-439 in the old code), replacing them with arithmetic (2 abs + 1 div + 1 comparison per endpoint). The ray sort key also switches from real angle to pseudoangle (same ordering). Ray directions (dx, dz) are completely unchanged -- the atan2 + cos/sin for epsilon rays remain for FP parity.

The pseudoangle-based buckets are non-uniform in real angle space: buckets near cardinal directions (0, pi/2, pi, -pi/2) cover wider angular ranges than buckets near diagonals. The existing +-1 bucket expansion (safety margin) absorbs this without correctness impact. The load imbalance adds a small overhead to the intersection loop, partially offsetting the atan2 savings. Overall, the net effect is positive for most workloads.

**Note**: The earlier abandoned "pseudoangle" attempt (see below) replaced atan2 everywhere including ray generation, which caused different bucket distribution AND was a more invasive change. This attempt only replaces the bucketing atan2 while keeping all ray generation trig intact.

Impact varies by workload -- largest on medium-step cases where bucketing atan2 is a proportionally larger cost:

| # | Benchmark | Before | After | Change |
|---|-----------|--------|-------|--------|
| 03 | `60x44_crates_none_nosym_50_g1101_r4` | 162 ms | 128 ms | **-21%** |
| 06 | `90x44_crates_HnA_sym_20_g0100_r1` | 148 ms | 128 ms | **-14%** |
| 07 | `60x44_wtc_HnA_nosym_50_g0110_r4` | 407 ms | 355 ms | **-13%** |
| 08 | `60x44_crates_HnA_sym_100_g1011_r2` | 877 ms | 760 ms | **-13%** |
| 11 | `90x44_crates_DoW_sym_50_g0011_r2` | 646 ms | 548 ms | **-15%** |
| 18 | `44x30_wtc_SwpEng_sym_20_g1010_r8` | 271 ms | 238 ms | **-12%** |
| 19 | `90x44_crates_SwpEng_nosym_50_g1101_r2` | 361 ms | 305 ms | **-16%** |
| 20 | `60x44_wtc_SwpEng_sym_100_g0010_r1` | 1.11 s | 976 ms | **-12%** |
| 21 | `44x30_crates_Crucible_sym_10_g1000_r8` | 82 ms | 69 ms | **-16%** |
| 23 | `60x44_wtc_Crucible_sym_50_g0110_r4` | 515 ms | 442 ms | **-14%** |
| 26 | `44x30_crates_SnD_sym_20_g1000_r8` | 185 ms | 158 ms | **-15%** |
| 27 | `44x30_wtc_SnD_nosym_50_g0010_r1` | 156 ms | 134 ms | **-14%** |
| 28 | `90x44_crates_SnD_sym_100_g1101_r2` | 1.23 s | 1.06 s | **-14%** |

(Remaining benchmarks within noise +-3%; no regressions observed.)

Parity verified: all 41 comparison scenarios pass.

### 11. sin_cos() for epsilon ray generation

Replace separate `a.cos()` / `a.sin()` calls for epsilon rays with `a.sin_cos()`, which computes both values in a single call sharing range reduction. Two `sin_cos()` calls per endpoint replace four separate trig calls (2 cos + 2 sin).

On glibc/libm, `sin_cos()` produces bit-identical results to separate `sin()`/`cos()` calls, so FP parity is maintained. Verified via full parity test suite (41/41 pass).

Consistent 5-11% improvement across most benchmarks, no regressions:

| # | Benchmark | Before | After | Change |
|---|-----------|--------|-------|--------|
| 01 | `90x44_crates_none_nosym_10_g0000_r1` | 14.9 ms | 13.7 ms | **-8%** |
| 03 | `60x44_crates_none_nosym_50_g1101_r4` | 128 ms | 130 ms | noise |
| 05 | `44x30_wtc_HnA_nosym_10_g1001_r8` | 71.5 ms | 65.8 ms | **-8%** |
| 08 | `60x44_crates_HnA_sym_100_g1011_r2` | 760 ms | 770 ms | noise |
| 09 | `44x30_wtc_DoW_sym_10_g0110_r8` | 82.1 ms | 76.2 ms | **-7%** |
| 11 | `90x44_crates_DoW_sym_50_g0011_r2` | 548 ms | 542 ms | noise |
| 12 | `90x44_wtc_DoW_nosym_100_g1100_r1` | 789 ms | 737 ms | **-7%** |
| 15 | `44x30_crates_TipPt_sym_50_g1001_r4` | 281 ms | 258 ms | **-8%** |
| 16 | `90x44_wtc_TipPt_nosym_100_g0110_r1` | 836 ms | 769 ms | **-8%** |
| 17 | `60x44_crates_SwpEng_nosym_10_g0101_r4` | 55.4 ms | 49.2 ms | **-11%** |
| 20 | `60x44_wtc_SwpEng_sym_100_g0010_r1` | 1035 ms | 960 ms | **-7%** |
| 21 | `44x30_crates_Crucible_sym_10_g1000_r8` | 74.5 ms | 68.4 ms | **-8%** |
| 28 | `90x44_crates_SnD_sym_100_g1101_r2` | 1.13 s | 1.04 s | **-8%** |

(24/28 benchmarks improved 5-11%; 4 within noise; 0 regressions.)

**Note**: `sin_cos()` parity with separate calls is platform-dependent. On musl libc or non-x86 platforms, this must be re-verified. The optimization could be made conditional via `cfg` if needed.

### Cumulative improvement (all optimizations)
| Benchmark | Original | Current | Total improvement |
|---|---|---|---|
| visibility_50 | 872 ms | **~191 ms** | **-78%** |
| visibility_100 | 3.80 s | **~733 ms** | **-81%** |
| mission_hna | 5.70 s | **~364 ms** | **-94%** |
| mission_ruins | n/a | **~192 ms** | n/a |

*Note: cumulative table uses old benchmark names from before the 28-case refactor. The FxHash optimization (opt #9) provides a further ~7-15% across the board on top of previous optimizations. Run-to-run variance makes precise cumulative numbers difficult to pin down, but the improvement is consistent and statistically significant across all 28 cases.*

*Measured February 2026.*

### Architectural change: objective hidability refactoring (correctness fix)

The objective hidability algorithm was refactored to fix an obscuring terrain asymmetry bug (see `visibility.py` docstring for the full explanation). The old approach computed vis polys from DZ observers and PIP-tested objective sample points; the new approach computes vis polys from each objective-vicinity sample point and checks polygon-polygon intersection with the opponent's expanded DZ.

This is a correctness fix, not an optimization — it trades performance for correct handling of obscuring terrain. The new approach adds ~300-600 extra vis poly computations per full visibility pass (one per objective sample point, ~60-120 points per objective, ~5 objectives). These run sequentially in a post-loop pass, separate from the Rayon-parallelized main observer loop.

**Impact: significant regression on all mission workloads, non-mission unaffected.**

| # | Benchmark | Before | After | Change |
|---|-----------|--------|-------|--------|
| 01 | `90x44_crates_none_nosym_10_g0000_r1` | 13.7 ms | 14.3 ms | noise |
| 02 | `44x30_wtc_none_nosym_20_g1010_r8` | 36.1 ms | 36.1 ms | noise |
| 03 | `60x44_crates_none_nosym_50_g1101_r4` | 130 ms | 139 ms | noise |
| 04 | `44x30_wtc_none_nosym_100_g0111_r2` | 98.8 ms | 98.3 ms | noise |
| 05 | `44x30_wtc_HnA_nosym_10_g1001_r8` | 65.8 ms | 110 ms | **+67%** |
| 06 | `90x44_crates_HnA_sym_20_g0100_r1` | 128 ms | 277 ms | **+116%** |
| 07 | `60x44_wtc_HnA_nosym_50_g0110_r4` | 355 ms | 560 ms | **+58%** |
| 08 | `60x44_crates_HnA_sym_100_g1011_r2` | 760 ms | 1.63 s | **+114%** |
| 09 | `44x30_wtc_DoW_sym_10_g0110_r8` | 76.2 ms | 157 ms | **+106%** |
| 10 | `60x44_crates_DoW_nosym_20_g1001_r4` | 108 ms | 199 ms | **+84%** |
| 11 | `90x44_crates_DoW_sym_50_g0011_r2` | 548 ms | 1.16 s | **+112%** |
| 12 | `90x44_wtc_DoW_nosym_100_g1100_r1` | 737 ms | 1.74 s | **+136%** |
| 13 | `60x44_wtc_TipPt_sym_10_g1010_r2` | 62.3 ms | 114 ms | **+83%** |
| 14 | `44x30_crates_TipPt_nosym_20_g0101_r8` | 141 ms | 267 ms | **+89%** |
| 15 | `44x30_crates_TipPt_sym_50_g1001_r4` | 258 ms | 568 ms | **+120%** |
| 16 | `90x44_wtc_TipPt_nosym_100_g0110_r1` | 769 ms | 1.86 s | **+142%** |
| 17 | `60x44_crates_SwpEng_nosym_10_g0101_r4` | 49.2 ms | 111 ms | **+126%** |
| 18 | `44x30_wtc_SwpEng_sym_20_g1010_r8` | 238 ms | 423 ms | **+78%** |
| 19 | `90x44_crates_SwpEng_nosym_50_g1101_r2` | 305 ms | 652 ms | **+114%** |
| 20 | `60x44_wtc_SwpEng_sym_100_g0010_r1` | 960 ms | 3.52 s | **+267%** |
| 21 | `44x30_crates_Crucible_sym_10_g1000_r8` | 68.4 ms | 166 ms | **+143%** |
| 22 | `60x44_wtc_Crucible_nosym_20_g0111_r2` | 91.4 ms | 164 ms | **+79%** |
| 23 | `60x44_wtc_Crucible_sym_50_g0110_r4` | 442 ms | 755 ms | **+71%** |
| 24 | `90x44_crates_Crucible_nosym_100_g1001_r1` | 712 ms | 1.37 s | **+92%** |
| 25 | `60x44_wtc_SnD_nosym_10_g0111_r4` | 66.0 ms | 119 ms | **+80%** |
| 26 | `44x30_crates_SnD_sym_20_g1000_r8` | 170 ms | 415 ms | **+144%** |
| 27 | `44x30_wtc_SnD_nosym_50_g0010_r1` | 134 ms | 514 ms | **+284%** |
| 28 | `90x44_crates_SnD_sym_100_g1101_r2` | 1.04 s | 1.98 s | **+90%** |
| 29 | `60x44_wtcPoly_none_nosym_20_g0101_r4` | 54.8 ms | 42.8 ms | noise |
| 30 | `44x30_wtcPoly_HnA_sym_10_g1010_r8` | 133 ms | 289 ms | **+117%** |
| 31 | `90x44_wtcPoly_DoW_nosym_50_g0011_r2` | 508 ms | 882 ms | **+74%** |
| 32 | `60x44_wtcPoly_TipPt_sym_100_g1100_r1` | 1.60 s | 2.30 s | **+44%** |
| 33 | `44x30_wtcPoly_SwpEng_nosym_10_g0110_r8` | 58.2 ms | 114 ms | **+96%** |
| 34 | `90x44_wtcPoly_Crucible_sym_20_g1001_r1` | 222 ms | 480 ms | **+116%** |
| 35 | `44x30_wtcPoly_SnD_sym_50_g0000_r2` | 356 ms | 1.25 s | **+251%** |

**Observations:**

- Non-mission workloads (01-04, 29) are unaffected — the objective hidability code path is not reached when there are no objectives.
- Mission workloads regress by **+44% to +284%**, with most in the +80-140% range. The plan estimated "roughly doubles vis poly work"; actual impact varies by mission type and step count.
- Worst regressions are on cases where the ratio of objective vis poly work to total work is highest: low step counts (less generation work to amortize against), symmetric layouts (more terrain → more segments per vis poly), and missions with objectives far from terrain (more sample points with non-trivial vis polys).
- Case 20 (SwpEng sym 100 r1) is the new heaviest at 3.52s (was 960ms). Case 35 (SnD sym 50 r2) jumped from 356ms to 1.25s.
- The objective vis poly pass is **sequential** (not parallelized with Rayon), so on multi-core machines it becomes the new bottleneck. Parallelizing this pass (see Tier 3 optimization ideas) is the most obvious recovery path.

*Measured February 2026.*

### FP parity reversions (post-optimization correctness fixes)

Three micro-optimizations were reverted because they produced different IEEE 754 floating-point results than the Python engine, breaking bit-identical parity:

1. **Trig reduction (opt #2)**: Rotation matrix for ±eps rays → reverted to `cos(angle ± eps)` / `sin(angle ± eps)`. Cost: +4 trig calls per endpoint.
2. **Precomputed inv_dz (opt #5 micro-opt)**: `1.0 / (zj - zi)` then multiply → reverted to direct division `/ (zj - zi)`. Cost: 1 division per edge per Z-range point instead of 1 multiply.
3. **Ray normalization inv_len**: `dx * (1.0 / len)` → reverted to `dx / len`. Cost: negligible (1 division vs 1 multiply, once per endpoint).

**Lesson learned**: Any arithmetic expression that produces values used in boundary tests (PIP edge crossings, visibility polygon vertices fed to DZ PIP) must use the exact same FP expression order as Python. `a * b * (1/c)` ≠ `a * b / c` and `cos(atan2(y,x) ± eps)` ≠ rotation matrix at IEEE 754 level.

## Attempted But Abandoned

### Segment-first loop reordering
Flip ray-outer/segment-inner to segment-outer/ray-inner with a `min_t[]` array (like `batch_point_in_polygon` does for PIP). The idea was to keep segment data in registers while scanning rays linearly.

**Result**: No clear improvement (±3% noise). The array-based `min_t` prevents register allocation of the per-ray minimum, and LLVM already does a good job with the original loop.

### Precomputed segment data
Precompute `(sx, sz, d_x1, d_z1, num_t)` per segment before the ray loop to avoid redundant arithmetic.

**Result**: Made things **worse** (~+15%). The 40-byte precomputed tuples increased the inner loop's memory footprint. The original 32-byte segment tuples with recomputed arithmetic were faster due to better cache behavior.

### AABB pre-filter on batch_point_in_polygon
Compute the bounding box of the visibility polygon and build a candidates list of points inside the AABB. Only run the edge-crossing loop on candidates. The idea was to skip 60-80% of DZ points when the vis polygon is small.

**Result**: No improvement on mission_hna. With sparse terrain, each observer's visibility polygon covers nearly the entire table, so the AABB filter skips almost nothing while adding overhead. The AABB filter has fundamentally wrong assumptions about the problem: in visibility analysis, most observers see most of the table.

### Pseudoangle (replacing atan2)
Replace atan2 with a cheap pseudoangle function `p = dx / (|dx| + |dz|)` that maps monotonically to [0, 4). Eliminates all atan2 calls (ray generation + bucket assignment).

**Result**: Mixed. Helped visibility_50 (-19%) and visibility_100 (-14%), but mission_hna regressed (+12%). The pseudoangle maps non-linearly to real angles, causing uneven bucket distribution. Buckets near the cardinal axes become wider (more segments), creating load imbalance. **Worth retrying with a clean machine.**

### OBB caching in is_valid_placement (4a)
Compute OBBs with height info once per feature via `get_world_obbs_with_height()` returning `Vec<(Corners, f64)>`, then reuse for overlap, all-feature-gap, tall-edge-gap, and tall-feature-gap checks. Also avoids cloning `PlacedFeature` structs into the `other_features` Vec by computing mirror OBBs directly via `get_mirror_obbs_with_height()`.

**Result**: No improvement. All 28 benchmarks within noise (+-2%). The reason: with typical layouts of 5-15 features (each having 1-3 shapes), the redundant OBB computation amounts to maybe 30-90 extra transform/trig operations per `is_valid_placement` call. This is negligible compared to the visibility computation that dominates total runtime. Additionally, `is_valid_placement` frequently early-exits on the overlap check (step 2) before reaching the gap checks (steps 2c, 3, 4) where the redundancy is worst, further limiting the potential savings. Not worth retrying -- the OBB path is simply not a bottleneck.

## Profiling Results

### Historical — pre-polygon-intersection (no longer current)

The following profiles were taken before the DZ visibility refactor and are retained for reference. The `dz_vis` and `cross_dz` phases no longer exist in their old form — they have been replaced by polygon-polygon intersection.

<details>
<summary>Post-Z-sorted-dz_vis, pre-Z-sorted-cross_dz (mission_hna)</summary>

Late-game steps (~760 observers, ~20 segments):

| Phase | Thread-ms | % of observer loop |
|---|---|---|
| `compute_visibility_polygon` | 30-50 | **~15-18%** |
| `dz_vis` (Z-sorted) | 20-30 | **~9-12%** |
| `cross_dz` (batch PIP) | 100-130 | **~45-50%** |
| `obj_hide` (batch PIP) | 55-80 | **~25-30%** |

</details>

<details>
<summary>Post-rayon, pre-Z-sorted (mission_hna)</summary>

| Phase | Thread-ms | % of observer loop |
|---|---|---|
| `get_observer_segments` | 0.2 | ~0.04% |
| `compute_visibility_polygon` | 35-48 | **~8%** |
| `dz_vis` (fraction_of_dz_visible_batch) | 270-330 | **~60%** |
| `cross_dz` (batch_point_in_polygon) | 120-148 | **~27%** |
| `obj_hide` (batch_point_in_polygon) | 30-47 | **~7%** |

</details>

### Current state: needs re-profiling (post pseudoangle + FxHash)

The polygon-polygon intersection refactor and subsequent optimizations (FxHash, pseudoangle bucketing) have significantly changed the bottleneck distribution. The old DZ PIP phases (`dz_vis`, `cross_dz`) are replaced by `polygons_overlap` calls. Bucketing atan2 has been eliminated. Fresh profiling is needed. Expected phases:

- `compute_visibility_polygon` — ray generation (atan2 + cos/sin per endpoint) + intersection loop (dominant for high-segment workloads)
- `dz_hideability` — polygon-polygon intersection per observer per opponent DZ
- `obj_hidability` — vis poly from each objective sample point + polygon-polygon intersection with expanded DZ
- `overall_pip` — polygon area (shoelace, likely cheap)

## Future Optimization Ideas (Not Yet Tried)

Organized by expected impact. Updated after polygon-intersection refactor.

### Tier 1: Polygon collision and overlap optimization

The `polygons_overlap()` function (in `collision.rs`) uses edge-edge intersection + vertex containment. AABB early-exit has been added (opt #8) via `polygons_overlap_aabb()` with precomputed DZ AABBs. With polygon terrain shapes (24-gon tank, 20-vertex woods), this path is now exercised much more heavily — `is_valid_placement` dispatches to `polygons_overlap` whenever a polygon shape is involved, and `obb_distance` iterates all edges.

#### 1a. SAT for convex polygons
The 24-gon tank is convex. SAT (Separating Axis Theorem) works for any pair of convex polygons — not just rectangles. For convex-vs-convex overlap, SAT tests (N_a + N_b) axes with early exit, vs the current `polygons_overlap` which does O(E_a × E_b) edge intersection tests. For a 24-gon vs 4-rect, SAT tests 28 axes vs 96 edge pairs. For 24-gon vs 24-gon, SAT tests 48 axes vs 576 edge pairs. The `obbs_overlap` function already implements SAT for 4-vertex shapes; generalizing to N-gon would be straightforward. Note: convexity must be checked or asserted, and non-convex polygons (like the kidney-bean woods with its concave notch) must still use `polygons_overlap`.

#### 1b. Spatial acceleration for edge-edge tests
If expanded DZ polygons have many edges (shapely buffer can produce ~20-50 points per polygon), the O(E_vis × E_dz) edge test becomes significant. Precomputing a spatial index (e.g., grid-based or segment tree) on the static DZ polygon edges could reduce per-observer work. Likely diminishing returns now that AABB eliminates the non-overlapping cases entirely.

#### 1c. AABB early-exit for terrain-vs-terrain polygon overlap
Opt #8 added AABB early-exit for DZ polygon overlap (precomputed DZ AABBs). The same technique could apply to terrain-vs-terrain overlap in `is_valid_placement` — precompute AABBs for placed features and check AABB overlap before the expensive `polygons_overlap` call. This matters more now that polygon terrain (24 edges) is in play.

### Tier 2: Raycasting refinements (dominant for non-mission workloads)

With DZ PIP eliminated as a bottleneck, raycasting (`compute_visibility_polygon`) is likely the dominant cost again for mission workloads as well as non-mission. These ideas target the angular sweep hot loop.

#### ~~2a. Pseudoangle hybrid~~ (DONE — see opt #10)
Pseudoangle for bucket assignment and sort keys. 12-21% improvement on medium workloads.

#### ~~2b. Faster endpoint deduplication~~ (DONE — see opt #9)
Replaced SipHash with inline FxHash for all integer-keyed hash sets/maps. 5-21% improvement across all workloads.

#### 2c. SIMD intersection
Manually vectorize the ray-segment intersection using `std::arch` SIMD intrinsics. Complex to implement and maintain. Low priority unless profiling shows raycasting > 50%.

#### 2d. Polygon segment reduction for visibility
The 24-gon tank generates 24 visibility segments, but many adjacent edges are nearly collinear (15° apart). Merging near-collinear consecutive edges into fewer segments before the angular sweep would reduce both the bucketing and intersection work. Must preserve FP parity — would need to be applied identically in Python. Alternatively, approximate circles with fewer sides (e.g., 12-gon instead of 24-gon) at the catalog level, though this changes the terrain geometry.

### Tier 3: Objective hidability (now uses vis-poly-from-objective + polygon intersection)

Objective hidability was refactored: instead of testing objective sample points against DZ-observer vis polys (PIP), it now computes a vis poly from each objective-vicinity sample point and checks polygon-polygon intersection with expanded DZ polygons. This is algorithmically correct for obscuring terrain (see `visibility.py` docstring) and eliminates Z-sorted PIP from production code.

The new approach computes ~60-120 extra vis polys per objective (one per sample point in the range circle), reused across all DZs. With ~5 objectives, that's ~300-600 vis poly computations on top of the main observer loop's ~600+. This roughly doubles the vis poly work for mission workloads, but only for the full visibility pass (not `overall_only`, which is the hot path during scoring).

Benchmarks show **+44% to +284% regression** on mission workloads (see "Architectural change" section above). This is now the dominant cost for mission benchmarks — the sequential objective pass can take longer than the entire parallelized observer loop.

Potential optimizations (in priority order):
- **3a. Parallelization** (HIGH PRIORITY): The per-objective vis poly computations are independent and could use `par_iter`. Currently sequential. Given the regression magnitude, this is the single most impactful recovery path — it would spread the ~300-600 vis poly computations across all available cores. Must collect results in index order for determinism.
- **3b. Early termination**: If a DZ already has all objectives marked as safe/unsafe, skip remaining intersection tests.
- **3c. AABB pre-filter**: Same `polygons_overlap_aabb` technique used for DZ hideability could be applied here (already using it).

### Tier 4: Collision / mutation path (affects all workloads, especially polygon catalogs)

#### ~~4a. Redundant OBB computation in is_valid_placement~~ (ABANDONED — see "Attempted But Abandoned")
Tested: no measurable improvement. OBB path is not a bottleneck (5-15 features * 1-3 shapes, early exit on overlap). **Note**: this was tested before polygon shapes existed. With polygon shapes (20-24 vertices), the cost of `shape_world_corners()` (rotating all vertices) and `polygons_overlap()` (O(E²) edge tests) is higher per call. May be worth re-evaluating if profiling shows collision is now a meaningful fraction with polygon catalogs.

#### 4b. Mirror feature cloning in hot paths
Mirror features for rotationally symmetric layouts are cloned into a fresh Vec on every call. Could precompute mirrors once per step, or use lazy iterator adapters.

#### 4c. `obb_distance` with polygon shapes
`obb_distance` computes minimum distance between two shapes via edge-to-edge and vertex-to-edge distances. With a 24-gon, this iterates 24 edges × M edges of the other shape, plus 24 vertex-to-edge tests. For gap enforcement (`min_feature_gap_inches`, `min_all_feature_gap_inches`), this is called for every pair of placed features. Convex polygon distance can be computed in O(log N + log M) via rotating calipers or GJK, but these are complex to implement and must preserve parity.

### Tier 5: Tempering / allocation overhead

#### 5a. Pre-allocate sub_undos
`Vec::with_capacity(num_mutations)` allocated fresh for every step of every replica. Could reuse with `clear()`.

#### 5b. Layout cloning on swap and best-tracking
Full `TerrainLayout` cloned on replica swaps. Could use COW semantics.

### Tier 6: Algorithmic / architectural (high complexity, speculative)

#### 6a. Incremental visibility
Only recompute observers affected by a mutation. Extremely complex, especially with DZ/objective accumulation. Risk of subtle correctness bugs.

### Recommended next steps

1. **Parallelize objective hidability vis poly pass (3a)** — this is now the top priority. The sequential objective pass is the single largest regression from the hidability refactoring (+44-284% on mission workloads). The per-sample-point vis poly computations are independent and map naturally to `par_iter`. This alone should recover most of the regression on multi-core machines.
2. **Re-profile with wtcPoly catalog** to understand where polygon overhead concentrates. The wtcPoly cases are 1.5-2x slower than rect-only — profiling will reveal whether the cost is dominated by collision (`polygons_overlap`, `obb_distance`), visibility (`precompute_segments` with 24-edge shapes), or both. Use `cargo bench -- wtcPoly` to isolate polygon cases.
3. **Try 1a (SAT for convex polygons)** — the 24-gon tank is convex, so SAT overlap testing (28 axes for 24-gon vs rect) should be much cheaper than the current O(E_a × E_b) edge intersection (96 pairs). This is the most direct attack on the polygon collision overhead.
4. **Try 1c (AABB early-exit for terrain overlap)** — cheap to implement, may help when polygon shapes don't overlap most placed features.
5. **Consider 2d (polygon segment reduction)** — if profiling shows visibility with 24-gon shapes is a hotspot, merging near-collinear edges could cut segment count significantly.

**Note**: The objective hidability refactoring is now the dominant performance concern for mission workloads. Previous optimization work focused on the main observer loop (raycasting, DZ PIP → polygon intersection), which is parallelized. The new objective pass is sequential and can take longer than the entire parallelized observer loop on high-step symmetric cases.
